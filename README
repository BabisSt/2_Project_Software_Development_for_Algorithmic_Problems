2η Εργασία Ανάπτυξη Λογισμικού για Αλγοριθμικά Προβλήματα 

	ΝΙΚΑΝΔΡΟΥ ΝΙΚΟΛΑΣ sdi1800224
	ΣΤΕΒΗΣ ΧΑΡΑΛΑΜΠΟΣ - ΑΝΤΩΝΙΟΣ sdi1600278
	
Από τι αποτελείται η εργασία:
	Φάκελος assets:		Εκεί θα μπουν τα αρχεία των dataset
	Φάκελος bin:		Εκεί μπαίνουν τα εκτελέσιμα
	Φάκελος build:		Εκεί μπαίνουν τα .ο
	Φάκελος include:	Εκεί βρίσκονται τα .h
	Φάκελοσ logs:		Εκεί βρίσκεται το αρχείο logs.txt που έχει τις εκτυπώσεις της εργασίας
	Φάκελος src:		Εκεί βρίσκονται τα .cpp
	cluster.conf
	Makefile
	README

Πως τρέχει η εργασία:
	Αφού κάνουμε make στην εργασία υπάρχουν δύο τρόποι για να τρέξει. 
	Ο 1ος είναι να μπούμε στον φάκελο bin και να τρέξουμε τις εντολές όπως λέει η εκφώνηση.
	Ο 2ος είναι να τρέξουμε έτοιμες εντολές από το Makefile όπως για π.χ run-lsh, run-hc, run-fr, run-cluster-classic, run-cluster-lsh, run-cluster-hc.
	Σε μερικές από αυτές τις εντολές δεν δίνονται όλα τα ορόσματα οπότε η εργασία δίνει τα default.
	
	Αν η εκτέλεση γίνει με τον πρώτο τρόπο τότε η εργασία ζητάει input, query files ενώ αν γίνει με τον δεύτερο
	τρέχει κατευθείαν με τα αρχεία που βρήκε στο Makefile. Στην συνέχεια η εργασία δίνει την δυνατότητα να ξανατρέξει
	με διαφοτερικά στοιχεία.
	
	Τα αποτελέσματα της εργασίας όπως είπαμε παραπάνω βρίσκονται στο αρχείο logs/logs.txt

Τι μπορεί να κάνει η εργασία:
	Η εργασία ανοίγει το dataset το διαβάζει και το αποθηκεύει, τόσο για input όσο και για query. 
	Στην συνέχεια λειτουγεί ανάλογα αν είμαστε σε cluster mode ή όχι.
	Αν όχι διαβάζει queries και δημιουργεί lsh ή hypercube χρισιμοποιόντας Descrete Frechet για να υπολογίσει τις αποστάσεις μεταξύ των καμπυλών.
	Η LSH μπορεί να βρίσκει χρόνους και να κάνει τις απαραίτητες εκτυπώσεις και με brute force και με get closest neighbors.
	Κάνει hash τα data που παίρνει από τα hashtables (θα πούμε παρακάτω), βρίσκει τις g και εκτελεί τα queries.
	H hypercube πέρα από τα παραπάνω δημιουργεί τις f και υπολογίζει τις hamming distances.
	Στα hashtables υπολογίζουμε την hashfunction από τα κομμάτια που αποτελείται και φτίαχνουμε τα tables με τα buckets τους.